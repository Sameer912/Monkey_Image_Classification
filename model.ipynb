{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this image classification tutorial, we use PyTorch programming framework. This tutorial will be carried out in three steps: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from load_data import Data_Loader, show_transformed_images\n",
    "import torchvision.models as models \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader= Data_Loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting the device to GPU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(): \n",
    "    if torch.cuda.is_available(): \n",
    "        dev= \"cuda:6\"\n",
    "    else: \n",
    "        dev= \"cpu\"\n",
    "    return torch.device(dev)\n",
    "\n",
    "device= set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model we are going to be using in this case is ResNet which has already been trained on image dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipendra/anaconda3/envs/TORCH/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dipendra/anaconda3/envs/TORCH/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet18_model= models.resnet18(pretrained= False)\n",
    "num_features= resnet18_model.fc.in_features\n",
    "num_classes= 10                                             #10 monkey species\n",
    "resnet18_model.fc= nn.Linear(num_features, num_classes)     #Modifying the fully connected layer of the model to match our prediction task \n",
    "resnet18_model= resnet18_model.to(device)                   #Setting the training to GPU        \n",
    "\n",
    "loss_fn= nn.CrossEntropyLoss()\n",
    "optimizer= optim.SGD(resnet18_model.parameters(), lr= 0.01, momentum= 0.9, weight_decay= 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, train_loader, test_loader, loss, optimizer, n_epochs, patience): \n",
    "    device= set_device()\n",
    "    counter= 0\n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        print(\"Epoch number %d\" % (epoch+1))\n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        running_correct= 0.\n",
    "        total= 0 \n",
    "        best_acc= 0\n",
    "        \n",
    "        for data in train_loader: \n",
    "            images, labels= data \n",
    "            images= images.to(device)\n",
    "            labels= labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()       #Seting the gradients to zero before back propagation \n",
    "            \n",
    "            outputs= model(images)\n",
    "            \n",
    "            _, predicted= torch.max(outputs.data, 1)\n",
    "            \n",
    "            losses= loss(outputs, labels)\n",
    "            losses.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += losses.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "        \n",
    "        epoch_loss= running_loss/len(train_loader)\n",
    "        epoch_accuracy= 100.0 * running_correct/total\n",
    "        \n",
    "        print(\"-Training dataset. Got %d out of %d images correctly. acc: %.3f%%. Epoch loss: %.3f\" \n",
    "              % (running_correct, total, epoch_accuracy,epoch_loss))\n",
    "        \n",
    "        validation_accuracy= evaluate_model(model, test_loader)\n",
    "        \n",
    "        if (validation_accuracy > best_acc): \n",
    "            best_acc= validation_accuracy\n",
    "            save_checkpoint(model, epoch, optimizer, best_acc)\n",
    "        \n",
    "        else: \n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= patience: \n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    print(\"Finished\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function for evaluating the performance of the model on validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader): \n",
    "    model.eval()\n",
    "    predicted_correctly= 0\n",
    "    total= 0\n",
    "    device= set_device()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data in test_loader: \n",
    "            images, labels= data\n",
    "            images= images.to(device)\n",
    "            labels= labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            outputs= model(images)\n",
    "            _, predicted= torch.max(outputs.data, 1) \n",
    "            \n",
    "            predicted_correctly += (predicted==labels).sum().item()\n",
    "   \n",
    "    epoch_acc= 100.0 * predicted_correctly/total\n",
    "    \n",
    "    print(\"-Testing dataset. Got %d out of %d images correctly. acc: %.3f%%\" % (predicted_correctly, total, epoch_acc))\n",
    "    \n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function for saving the checkpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, optimizer, best_acc): \n",
    "    state= {\n",
    "        \"epoch\": epoch + 1, \n",
    "        \"model\": model.state_dict(),\n",
    "        \"best_accuracy\": best_acc,\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"comments\": \"Monkey classification model\" \n",
    "    }\n",
    "    \n",
    "    torch.save(state, \"checkpoints/model_best_checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1\n",
      "-Training dataset. Got 275 out of 1097 images correctly. acc: 25.068%. Epoch loss: 2.168\n",
      "-Testing dataset. Got 38 out of 272 images correctly. acc: 13.971%\n",
      "Epoch number 2\n",
      "-Training dataset. Got 389 out of 1097 images correctly. acc: 35.460%. Epoch loss: 1.848\n",
      "-Testing dataset. Got 80 out of 272 images correctly. acc: 29.412%\n",
      "Epoch number 3\n",
      "-Training dataset. Got 476 out of 1097 images correctly. acc: 43.391%. Epoch loss: 1.613\n",
      "-Testing dataset. Got 113 out of 272 images correctly. acc: 41.544%\n",
      "Epoch number 4\n",
      "-Training dataset. Got 525 out of 1097 images correctly. acc: 47.858%. Epoch loss: 1.514\n",
      "-Testing dataset. Got 108 out of 272 images correctly. acc: 39.706%\n",
      "Epoch number 5\n",
      "-Training dataset. Got 528 out of 1097 images correctly. acc: 48.131%. Epoch loss: 1.461\n",
      "-Testing dataset. Got 136 out of 272 images correctly. acc: 50.000%\n",
      "Epoch number 6\n",
      "-Training dataset. Got 643 out of 1097 images correctly. acc: 58.614%. Epoch loss: 1.182\n",
      "-Testing dataset. Got 141 out of 272 images correctly. acc: 51.838%\n",
      "Epoch number 7\n",
      "-Training dataset. Got 688 out of 1097 images correctly. acc: 62.716%. Epoch loss: 1.026\n",
      "-Testing dataset. Got 130 out of 272 images correctly. acc: 47.794%\n",
      "Epoch number 8\n",
      "-Training dataset. Got 699 out of 1097 images correctly. acc: 63.719%. Epoch loss: 1.003\n",
      "-Testing dataset. Got 134 out of 272 images correctly. acc: 49.265%\n",
      "Epoch number 9\n",
      "-Training dataset. Got 707 out of 1097 images correctly. acc: 64.448%. Epoch loss: 0.954\n",
      "-Testing dataset. Got 147 out of 272 images correctly. acc: 54.044%\n",
      "Epoch number 10\n",
      "-Training dataset. Got 739 out of 1097 images correctly. acc: 67.366%. Epoch loss: 0.949\n",
      "-Testing dataset. Got 144 out of 272 images correctly. acc: 52.941%\n",
      "Epoch number 11\n",
      "-Training dataset. Got 788 out of 1097 images correctly. acc: 71.832%. Epoch loss: 0.799\n",
      "-Testing dataset. Got 159 out of 272 images correctly. acc: 58.456%\n",
      "Epoch number 12\n",
      "-Training dataset. Got 828 out of 1097 images correctly. acc: 75.479%. Epoch loss: 0.719\n",
      "-Testing dataset. Got 157 out of 272 images correctly. acc: 57.721%\n",
      "Epoch number 13\n",
      "-Training dataset. Got 849 out of 1097 images correctly. acc: 77.393%. Epoch loss: 0.642\n",
      "-Testing dataset. Got 149 out of 272 images correctly. acc: 54.779%\n",
      "Epoch number 14\n",
      "-Training dataset. Got 865 out of 1097 images correctly. acc: 78.851%. Epoch loss: 0.659\n",
      "-Testing dataset. Got 173 out of 272 images correctly. acc: 63.603%\n",
      "Epoch number 15\n",
      "-Training dataset. Got 911 out of 1097 images correctly. acc: 83.045%. Epoch loss: 0.489\n",
      "-Testing dataset. Got 129 out of 272 images correctly. acc: 47.426%\n",
      "Epoch number 16\n",
      "-Training dataset. Got 925 out of 1097 images correctly. acc: 84.321%. Epoch loss: 0.449\n",
      "-Testing dataset. Got 173 out of 272 images correctly. acc: 63.603%\n",
      "Epoch number 17\n",
      "-Training dataset. Got 923 out of 1097 images correctly. acc: 84.139%. Epoch loss: 0.467\n",
      "-Testing dataset. Got 193 out of 272 images correctly. acc: 70.956%\n",
      "Epoch number 18\n",
      "-Training dataset. Got 951 out of 1097 images correctly. acc: 86.691%. Epoch loss: 0.389\n",
      "-Testing dataset. Got 177 out of 272 images correctly. acc: 65.074%\n",
      "Epoch number 19\n",
      "-Training dataset. Got 967 out of 1097 images correctly. acc: 88.149%. Epoch loss: 0.330\n",
      "-Testing dataset. Got 193 out of 272 images correctly. acc: 70.956%\n",
      "Epoch number 20\n",
      "-Training dataset. Got 1009 out of 1097 images correctly. acc: 91.978%. Epoch loss: 0.251\n",
      "-Testing dataset. Got 208 out of 272 images correctly. acc: 76.471%\n",
      "Epoch number 21\n",
      "-Training dataset. Got 1010 out of 1097 images correctly. acc: 92.069%. Epoch loss: 0.234\n",
      "-Testing dataset. Got 182 out of 272 images correctly. acc: 66.912%\n",
      "Epoch number 22\n",
      "-Training dataset. Got 983 out of 1097 images correctly. acc: 89.608%. Epoch loss: 0.302\n",
      "-Testing dataset. Got 193 out of 272 images correctly. acc: 70.956%\n",
      "Epoch number 23\n",
      "-Training dataset. Got 1006 out of 1097 images correctly. acc: 91.705%. Epoch loss: 0.248\n",
      "-Testing dataset. Got 215 out of 272 images correctly. acc: 79.044%\n",
      "Epoch number 24\n",
      "-Training dataset. Got 1012 out of 1097 images correctly. acc: 92.252%. Epoch loss: 0.236\n",
      "-Testing dataset. Got 164 out of 272 images correctly. acc: 60.294%\n",
      "Epoch number 25\n",
      "-Training dataset. Got 1004 out of 1097 images correctly. acc: 91.522%. Epoch loss: 0.262\n",
      "-Testing dataset. Got 201 out of 272 images correctly. acc: 73.897%\n",
      "Epoch number 26\n",
      "-Training dataset. Got 1052 out of 1097 images correctly. acc: 95.898%. Epoch loss: 0.152\n",
      "-Testing dataset. Got 208 out of 272 images correctly. acc: 76.471%\n",
      "Epoch number 27\n",
      "-Training dataset. Got 1045 out of 1097 images correctly. acc: 95.260%. Epoch loss: 0.146\n",
      "-Testing dataset. Got 197 out of 272 images correctly. acc: 72.426%\n",
      "Epoch number 28\n",
      "-Training dataset. Got 1042 out of 1097 images correctly. acc: 94.986%. Epoch loss: 0.166\n",
      "-Testing dataset. Got 203 out of 272 images correctly. acc: 74.632%\n",
      "Epoch number 29\n",
      "-Training dataset. Got 1024 out of 1097 images correctly. acc: 93.345%. Epoch loss: 0.208\n",
      "-Testing dataset. Got 205 out of 272 images correctly. acc: 75.368%\n",
      "Epoch number 30\n",
      "-Training dataset. Got 1038 out of 1097 images correctly. acc: 94.622%. Epoch loss: 0.182\n",
      "-Testing dataset. Got 185 out of 272 images correctly. acc: 68.015%\n",
      "Epoch number 31\n",
      "-Training dataset. Got 1034 out of 1097 images correctly. acc: 94.257%. Epoch loss: 0.176\n",
      "-Testing dataset. Got 191 out of 272 images correctly. acc: 70.221%\n",
      "Epoch number 32\n",
      "-Training dataset. Got 1063 out of 1097 images correctly. acc: 96.901%. Epoch loss: 0.107\n",
      "-Testing dataset. Got 216 out of 272 images correctly. acc: 79.412%\n",
      "Epoch number 33\n",
      "-Training dataset. Got 1043 out of 1097 images correctly. acc: 95.077%. Epoch loss: 0.152\n",
      "-Testing dataset. Got 206 out of 272 images correctly. acc: 75.735%\n",
      "Epoch number 34\n",
      "-Training dataset. Got 1064 out of 1097 images correctly. acc: 96.992%. Epoch loss: 0.089\n",
      "-Testing dataset. Got 214 out of 272 images correctly. acc: 78.676%\n",
      "Epoch number 35\n",
      "-Training dataset. Got 1065 out of 1097 images correctly. acc: 97.083%. Epoch loss: 0.096\n",
      "-Testing dataset. Got 209 out of 272 images correctly. acc: 76.838%\n",
      "Epoch number 36\n",
      "-Training dataset. Got 1055 out of 1097 images correctly. acc: 96.171%. Epoch loss: 0.134\n",
      "-Testing dataset. Got 200 out of 272 images correctly. acc: 73.529%\n",
      "Epoch number 37\n",
      "-Training dataset. Got 1032 out of 1097 images correctly. acc: 94.075%. Epoch loss: 0.186\n",
      "-Testing dataset. Got 181 out of 272 images correctly. acc: 66.544%\n",
      "Epoch number 38\n",
      "-Training dataset. Got 1059 out of 1097 images correctly. acc: 96.536%. Epoch loss: 0.109\n",
      "-Testing dataset. Got 201 out of 272 images correctly. acc: 73.897%\n",
      "Epoch number 39\n",
      "-Training dataset. Got 1081 out of 1097 images correctly. acc: 98.541%. Epoch loss: 0.066\n",
      "-Testing dataset. Got 216 out of 272 images correctly. acc: 79.412%\n",
      "Epoch number 40\n",
      "-Training dataset. Got 1084 out of 1097 images correctly. acc: 98.815%. Epoch loss: 0.052\n",
      "-Testing dataset. Got 210 out of 272 images correctly. acc: 77.206%\n",
      "Epoch number 41\n",
      "-Training dataset. Got 1083 out of 1097 images correctly. acc: 98.724%. Epoch loss: 0.047\n",
      "-Testing dataset. Got 219 out of 272 images correctly. acc: 80.515%\n",
      "Epoch number 42\n",
      "-Training dataset. Got 1092 out of 1097 images correctly. acc: 99.544%. Epoch loss: 0.056\n",
      "-Testing dataset. Got 222 out of 272 images correctly. acc: 81.618%\n",
      "Epoch number 43\n",
      "-Training dataset. Got 1039 out of 1097 images correctly. acc: 94.713%. Epoch loss: 0.161\n",
      "-Testing dataset. Got 201 out of 272 images correctly. acc: 73.897%\n",
      "Epoch number 44\n",
      "-Training dataset. Got 1066 out of 1097 images correctly. acc: 97.174%. Epoch loss: 0.109\n",
      "-Testing dataset. Got 211 out of 272 images correctly. acc: 77.574%\n",
      "Epoch number 45\n",
      "-Training dataset. Got 1080 out of 1097 images correctly. acc: 98.450%. Epoch loss: 0.075\n",
      "-Testing dataset. Got 211 out of 272 images correctly. acc: 77.574%\n",
      "Epoch number 46\n",
      "-Training dataset. Got 1091 out of 1097 images correctly. acc: 99.453%. Epoch loss: 0.042\n",
      "-Testing dataset. Got 218 out of 272 images correctly. acc: 80.147%\n",
      "Epoch number 47\n",
      "-Training dataset. Got 1088 out of 1097 images correctly. acc: 99.180%. Epoch loss: 0.046\n",
      "-Testing dataset. Got 225 out of 272 images correctly. acc: 82.721%\n",
      "Epoch number 48\n",
      "-Training dataset. Got 1082 out of 1097 images correctly. acc: 98.633%. Epoch loss: 0.053\n",
      "-Testing dataset. Got 222 out of 272 images correctly. acc: 81.618%\n",
      "Epoch number 49\n",
      "-Training dataset. Got 1085 out of 1097 images correctly. acc: 98.906%. Epoch loss: 0.042\n",
      "-Testing dataset. Got 229 out of 272 images correctly. acc: 84.191%\n",
      "Epoch number 50\n",
      "-Training dataset. Got 1091 out of 1097 images correctly. acc: 99.453%. Epoch loss: 0.030\n",
      "-Testing dataset. Got 217 out of 272 images correctly. acc: 79.779%\n",
      "Epoch number 51\n",
      "-Training dataset. Got 1083 out of 1097 images correctly. acc: 98.724%. Epoch loss: 0.046\n",
      "-Testing dataset. Got 210 out of 272 images correctly. acc: 77.206%\n",
      "Epoch number 52\n",
      "-Training dataset. Got 1083 out of 1097 images correctly. acc: 98.724%. Epoch loss: 0.048\n",
      "-Testing dataset. Got 221 out of 272 images correctly. acc: 81.250%\n",
      "Epoch number 53\n",
      "-Training dataset. Got 1083 out of 1097 images correctly. acc: 98.724%. Epoch loss: 0.061\n",
      "-Testing dataset. Got 199 out of 272 images correctly. acc: 73.162%\n",
      "Epoch number 54\n",
      "-Training dataset. Got 1042 out of 1097 images correctly. acc: 94.986%. Epoch loss: 0.140\n",
      "-Testing dataset. Got 204 out of 272 images correctly. acc: 75.000%\n",
      "Epoch number 55\n",
      "-Training dataset. Got 1068 out of 1097 images correctly. acc: 97.356%. Epoch loss: 0.093\n",
      "-Testing dataset. Got 209 out of 272 images correctly. acc: 76.838%\n",
      "Epoch number 56\n",
      "-Training dataset. Got 1066 out of 1097 images correctly. acc: 97.174%. Epoch loss: 0.106\n",
      "-Testing dataset. Got 226 out of 272 images correctly. acc: 83.088%\n",
      "Epoch number 57\n",
      "-Training dataset. Got 1088 out of 1097 images correctly. acc: 99.180%. Epoch loss: 0.048\n",
      "-Testing dataset. Got 221 out of 272 images correctly. acc: 81.250%\n",
      "Epoch number 58\n",
      "-Training dataset. Got 1090 out of 1097 images correctly. acc: 99.362%. Epoch loss: 0.032\n",
      "-Testing dataset. Got 232 out of 272 images correctly. acc: 85.294%\n",
      "Epoch number 59\n",
      "-Training dataset. Got 1093 out of 1097 images correctly. acc: 99.635%. Epoch loss: 0.029\n",
      "-Testing dataset. Got 232 out of 272 images correctly. acc: 85.294%\n",
      "Epoch number 60\n",
      "-Training dataset. Got 1095 out of 1097 images correctly. acc: 99.818%. Epoch loss: 0.022\n",
      "-Testing dataset. Got 230 out of 272 images correctly. acc: 84.559%\n",
      "Epoch number 61\n",
      "-Training dataset. Got 1096 out of 1097 images correctly. acc: 99.909%. Epoch loss: 0.016\n",
      "-Testing dataset. Got 235 out of 272 images correctly. acc: 86.397%\n",
      "Epoch number 62\n",
      "-Training dataset. Got 1093 out of 1097 images correctly. acc: 99.635%. Epoch loss: 0.018\n",
      "-Testing dataset. Got 225 out of 272 images correctly. acc: 82.721%\n",
      "Epoch number 63\n",
      "-Training dataset. Got 1095 out of 1097 images correctly. acc: 99.818%. Epoch loss: 0.018\n",
      "-Testing dataset. Got 229 out of 272 images correctly. acc: 84.191%\n",
      "Epoch number 64\n",
      "-Training dataset. Got 1094 out of 1097 images correctly. acc: 99.727%. Epoch loss: 0.021\n",
      "-Testing dataset. Got 239 out of 272 images correctly. acc: 87.868%\n",
      "Epoch number 65\n",
      "-Training dataset. Got 1093 out of 1097 images correctly. acc: 99.635%. Epoch loss: 0.025\n",
      "-Testing dataset. Got 227 out of 272 images correctly. acc: 83.456%\n",
      "Epoch number 66\n",
      "-Training dataset. Got 1084 out of 1097 images correctly. acc: 98.815%. Epoch loss: 0.048\n",
      "-Testing dataset. Got 222 out of 272 images correctly. acc: 81.618%\n",
      "Epoch number 67\n",
      "-Training dataset. Got 1091 out of 1097 images correctly. acc: 99.453%. Epoch loss: 0.031\n",
      "-Testing dataset. Got 225 out of 272 images correctly. acc: 82.721%\n",
      "Epoch number 68\n",
      "-Training dataset. Got 1093 out of 1097 images correctly. acc: 99.635%. Epoch loss: 0.025\n",
      "-Testing dataset. Got 225 out of 272 images correctly. acc: 82.721%\n",
      "Epoch number 69\n",
      "-Training dataset. Got 1096 out of 1097 images correctly. acc: 99.909%. Epoch loss: 0.018\n",
      "-Testing dataset. Got 230 out of 272 images correctly. acc: 84.559%\n",
      "Epoch number 70\n",
      "-Training dataset. Got 1096 out of 1097 images correctly. acc: 99.909%. Epoch loss: 0.011\n",
      "-Testing dataset. Got 227 out of 272 images correctly. acc: 83.456%\n",
      "Epoch number 71\n",
      "-Training dataset. Got 1097 out of 1097 images correctly. acc: 100.000%. Epoch loss: 0.011\n",
      "-Testing dataset. Got 235 out of 272 images correctly. acc: 86.397%\n",
      "Epoch number 72\n",
      "-Training dataset. Got 1097 out of 1097 images correctly. acc: 100.000%. Epoch loss: 0.008\n",
      "-Testing dataset. Got 234 out of 272 images correctly. acc: 86.029%\n",
      "Epoch number 73\n",
      "-Training dataset. Got 1097 out of 1097 images correctly. acc: 100.000%. Epoch loss: 0.007\n",
      "-Testing dataset. Got 242 out of 272 images correctly. acc: 88.971%\n",
      "Epoch number 74\n",
      "-Training dataset. Got 1097 out of 1097 images correctly. acc: 100.000%. Epoch loss: 0.008\n",
      "-Testing dataset. Got 241 out of 272 images correctly. acc: 88.603%\n",
      "Epoch number 75\n",
      "-Training dataset. Got 1096 out of 1097 images correctly. acc: 99.909%. Epoch loss: 0.011\n",
      "-Testing dataset. Got 239 out of 272 images correctly. acc: 87.868%\n",
      "Epoch number 76\n",
      "-Training dataset. Got 1095 out of 1097 images correctly. acc: 99.818%. Epoch loss: 0.017\n",
      "-Testing dataset. Got 236 out of 272 images correctly. acc: 86.765%\n",
      "Epoch number 77\n",
      "-Training dataset. Got 1091 out of 1097 images correctly. acc: 99.453%. Epoch loss: 0.029\n",
      "-Testing dataset. Got 223 out of 272 images correctly. acc: 81.985%\n",
      "Epoch number 78\n",
      "-Training dataset. Got 1092 out of 1097 images correctly. acc: 99.544%. Epoch loss: 0.027\n",
      "-Testing dataset. Got 243 out of 272 images correctly. acc: 89.338%\n",
      "Epoch number 79\n",
      "-Training dataset. Got 1094 out of 1097 images correctly. acc: 99.727%. Epoch loss: 0.024\n",
      "-Testing dataset. Got 237 out of 272 images correctly. acc: 87.132%\n",
      "Epoch number 80\n",
      "-Training dataset. Got 1093 out of 1097 images correctly. acc: 99.635%. Epoch loss: 0.029\n",
      "-Testing dataset. Got 228 out of 272 images correctly. acc: 83.824%\n",
      "Epoch number 81\n",
      "-Training dataset. Got 1079 out of 1097 images correctly. acc: 98.359%. Epoch loss: 0.070\n",
      "-Testing dataset. Got 213 out of 272 images correctly. acc: 78.309%\n",
      "Epoch number 82\n",
      "-Training dataset. Got 1051 out of 1097 images correctly. acc: 95.807%. Epoch loss: 0.153\n",
      "-Testing dataset. Got 179 out of 272 images correctly. acc: 65.809%\n",
      "Epoch number 83\n",
      "-Training dataset. Got 1029 out of 1097 images correctly. acc: 93.801%. Epoch loss: 0.193\n",
      "-Testing dataset. Got 175 out of 272 images correctly. acc: 64.338%\n",
      "Epoch number 84\n",
      "-Training dataset. Got 1043 out of 1097 images correctly. acc: 95.077%. Epoch loss: 0.168\n",
      "-Testing dataset. Got 198 out of 272 images correctly. acc: 72.794%\n",
      "Epoch number 85\n",
      "-Training dataset. Got 1044 out of 1097 images correctly. acc: 95.169%. Epoch loss: 0.157\n",
      "-Testing dataset. Got 218 out of 272 images correctly. acc: 80.147%\n",
      "Epoch number 86\n",
      "-Training dataset. Got 1062 out of 1097 images correctly. acc: 96.809%. Epoch loss: 0.136\n",
      "-Testing dataset. Got 205 out of 272 images correctly. acc: 75.368%\n",
      "Epoch number 87\n",
      "-Training dataset. Got 1052 out of 1097 images correctly. acc: 95.898%. Epoch loss: 0.146\n",
      "-Testing dataset. Got 210 out of 272 images correctly. acc: 77.206%\n",
      "Epoch number 88\n",
      "-Training dataset. Got 1058 out of 1097 images correctly. acc: 96.445%. Epoch loss: 0.139\n",
      "-Testing dataset. Got 207 out of 272 images correctly. acc: 76.103%\n",
      "Epoch number 89\n",
      "-Training dataset. Got 1075 out of 1097 images correctly. acc: 97.995%. Epoch loss: 0.094\n",
      "-Testing dataset. Got 220 out of 272 images correctly. acc: 80.882%\n",
      "Epoch number 90\n",
      "-Training dataset. Got 1068 out of 1097 images correctly. acc: 97.356%. Epoch loss: 0.111\n",
      "-Testing dataset. Got 201 out of 272 images correctly. acc: 73.897%\n",
      "Epoch number 91\n",
      "-Training dataset. Got 1072 out of 1097 images correctly. acc: 97.721%. Epoch loss: 0.086\n",
      "-Testing dataset. Got 214 out of 272 images correctly. acc: 78.676%\n",
      "Epoch number 92\n",
      "-Training dataset. Got 1087 out of 1097 images correctly. acc: 99.088%. Epoch loss: 0.049\n",
      "-Testing dataset. Got 237 out of 272 images correctly. acc: 87.132%\n",
      "Epoch number 93\n",
      "-Training dataset. Got 1095 out of 1097 images correctly. acc: 99.818%. Epoch loss: 0.029\n",
      "-Testing dataset. Got 239 out of 272 images correctly. acc: 87.868%\n",
      "Epoch number 94\n",
      "-Training dataset. Got 1089 out of 1097 images correctly. acc: 99.271%. Epoch loss: 0.038\n",
      "-Testing dataset. Got 237 out of 272 images correctly. acc: 87.132%\n",
      "Epoch number 95\n",
      "-Training dataset. Got 1090 out of 1097 images correctly. acc: 99.362%. Epoch loss: 0.036\n",
      "-Testing dataset. Got 229 out of 272 images correctly. acc: 84.191%\n",
      "Epoch number 96\n",
      "-Training dataset. Got 1094 out of 1097 images correctly. acc: 99.727%. Epoch loss: 0.032\n",
      "-Testing dataset. Got 233 out of 272 images correctly. acc: 85.662%\n",
      "Epoch number 97\n",
      "-Training dataset. Got 1092 out of 1097 images correctly. acc: 99.544%. Epoch loss: 0.031\n",
      "-Testing dataset. Got 228 out of 272 images correctly. acc: 83.824%\n",
      "Epoch number 98\n",
      "-Training dataset. Got 1088 out of 1097 images correctly. acc: 99.180%. Epoch loss: 0.042\n",
      "-Testing dataset. Got 229 out of 272 images correctly. acc: 84.191%\n",
      "Epoch number 99\n",
      "-Training dataset. Got 1094 out of 1097 images correctly. acc: 99.727%. Epoch loss: 0.032\n",
      "-Testing dataset. Got 234 out of 272 images correctly. acc: 86.029%\n",
      "Epoch number 100\n",
      "-Training dataset. Got 1086 out of 1097 images correctly. acc: 98.997%. Epoch loss: 0.061\n",
      "-Testing dataset. Got 217 out of 272 images correctly. acc: 79.779%\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn(model= resnet18_model, train_loader= train_loader, test_loader= test_loader, loss= loss_fn, optimizer= optimizer, n_epochs= 100, patience= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint= torch.load(\"checkpoints/model_best_checkpoint.pth.tar\")\n",
    "resnet18_model.load_state_dict(checkpoint[\"model\"])\n",
    "torch.save(resnet18_model, \"saved_model/save_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
